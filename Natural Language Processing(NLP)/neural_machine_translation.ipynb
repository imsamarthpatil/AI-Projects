{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1385e05d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-18T13:51:33.363456Z",
     "iopub.status.busy": "2021-12-18T13:51:33.361965Z",
     "iopub.status.idle": "2021-12-18T13:51:38.379023Z",
     "shell.execute_reply": "2021-12-18T13:51:38.378132Z",
     "shell.execute_reply.started": "2021-12-18T13:27:28.253857Z"
    },
    "papermill": {
     "duration": 5.036714,
     "end_time": "2021-12-18T13:51:38.379184",
     "exception": false,
     "start_time": "2021-12-18T13:51:33.342470",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Shrirang Alias Samarth Patil\n",
    "# 19BAI10079\n",
    "\n",
    "# Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os,unicodedata, re, io, time, gc, warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from tabulate import tabulate\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8140508",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-18T13:51:38.415534Z",
     "iopub.status.busy": "2021-12-18T13:51:38.414988Z",
     "iopub.status.idle": "2021-12-18T13:51:38.676171Z",
     "shell.execute_reply": "2021-12-18T13:51:38.676782Z",
     "shell.execute_reply.started": "2021-12-18T13:27:32.758184Z"
    },
    "papermill": {
     "duration": 0.281178,
     "end_time": "2021-12-18T13:51:38.676987",
     "exception": false,
     "start_time": "2021-12-18T13:51:38.395809",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Records:  39961\n"
     ]
    }
   ],
   "source": [
    "# Dataset of Marathi to English\n",
    "data = '../input/marathi-english-sentence-pairs/mar.txt'\n",
    "df = pd.read_csv(data, sep='\\t',header=None, names=['Eng','Mar','Trn'])\n",
    "\n",
    "#Dropping the Trn Column\n",
    "df.drop('Trn',axis=1, inplace=True)\n",
    "\n",
    "#Shape\n",
    "print(\"Total Records: \", df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7bfe8a89",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-18T13:51:38.719624Z",
     "iopub.status.busy": "2021-12-18T13:51:38.718794Z",
     "iopub.status.idle": "2021-12-18T13:51:39.230947Z",
     "shell.execute_reply": "2021-12-18T13:51:39.231454Z",
     "shell.execute_reply.started": "2021-12-18T13:27:32.965321Z"
    },
    "papermill": {
     "duration": 0.538135,
     "end_time": "2021-12-18T13:51:39.231626",
     "exception": false,
     "start_time": "2021-12-18T13:51:38.693491",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English:  <start> he has 12 sons . <end>\n",
      "Marathi:  <start> त्याला १२ मुलं आहेत . <end>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Eng</th>\n",
       "      <th>Mar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;start&gt; go . &lt;end&gt;</td>\n",
       "      <td>&lt;start&gt; जा . &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;start&gt; run ! &lt;end&gt;</td>\n",
       "      <td>&lt;start&gt; पळ ! &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;start&gt; run ! &lt;end&gt;</td>\n",
       "      <td>&lt;start&gt; धाव ! &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;start&gt; run ! &lt;end&gt;</td>\n",
       "      <td>&lt;start&gt; पळा ! &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;start&gt; run ! &lt;end&gt;</td>\n",
       "      <td>&lt;start&gt; धावा ! &lt;end&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Eng                   Mar\n",
       "0   <start> go . <end>    <start> जा . <end>\n",
       "1  <start> run ! <end>    <start> पळ ! <end>\n",
       "2  <start> run ! <end>   <start> धाव ! <end>\n",
       "3  <start> run ! <end>   <start> पळा ! <end>\n",
       "4  <start> run ! <end>  <start> धावा ! <end>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#PreProcessing Function\n",
    "def preprocess(w):\n",
    "    w = w.lower().strip()\n",
    "    w = re.sub(r\"([?.!,¿।])\", r\" \\1 \", w)\n",
    "    w = w.strip()\n",
    "    w = '<start> ' + w + ' <end>'\n",
    "    return w\n",
    "\n",
    "#Applying PreProcess Function to a single sentence\n",
    "x = np.random.randint(1,df.shape[0])\n",
    "print(\"English: \", preprocess(df.Eng[x]))\n",
    "print(\"Marathi: \", preprocess(df.Mar[x]))\n",
    "\n",
    "#applying the preprocess function\n",
    "df['Eng'] = df['Eng'].apply(lambda x: preprocess(x))\n",
    "df['Mar'] = df['Mar'].apply(lambda x: preprocess(x))\n",
    "\n",
    "#Inspect\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b743371d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-18T13:51:39.269121Z",
     "iopub.status.busy": "2021-12-18T13:51:39.268301Z",
     "iopub.status.idle": "2021-12-18T13:51:42.218418Z",
     "shell.execute_reply": "2021-12-18T13:51:42.217488Z",
     "shell.execute_reply.started": "2021-12-18T13:27:33.487274Z"
    },
    "papermill": {
     "duration": 2.971555,
     "end_time": "2021-12-18T13:51:42.218570",
     "exception": false,
     "start_time": "2021-12-18T13:51:39.247015",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Tokenize Function\n",
    "def tokenize(lang):\n",
    "    lang_tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='')\n",
    "    lang_tokenizer.fit_on_texts(lang)\n",
    "\n",
    "    tensor = lang_tokenizer.texts_to_sequences(lang)\n",
    "    tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor,padding='post')\n",
    "\n",
    "    return tensor, lang_tokenizer\n",
    "\n",
    "\n",
    "'''Tokenize Column Data'''\n",
    "# Input = English || # Output = Marathi\n",
    "input_tensor, inp_lang = tokenize(df['Eng'])\n",
    "target_tensor, targ_lang = tokenize(df['Mar'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "61c2c007",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-18T13:51:42.256236Z",
     "iopub.status.busy": "2021-12-18T13:51:42.255667Z",
     "iopub.status.idle": "2021-12-18T13:51:42.272419Z",
     "shell.execute_reply": "2021-12-18T13:51:42.273003Z",
     "shell.execute_reply.started": "2021-12-18T13:27:36.625878Z"
    },
    "papermill": {
     "duration": 0.038856,
     "end_time": "2021-12-18T13:51:42.273198",
     "exception": false,
     "start_time": "2021-12-18T13:51:42.234342",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    Lengths\n",
      "----------------  ---------\n",
      "Eng Train Tensor      35964\n",
      "Mar Train Tensor      35964\n",
      "Eng Val Tensor         3997\n",
      "Mar Val Tensor         3997\n"
     ]
    }
   ],
   "source": [
    "# To train faster, we can limit the size of the dataset to 100 sentences \n",
    "num_examples = 100\n",
    "\n",
    "# Calculate max_length of the target tensors\n",
    "max_length_targ, max_length_inp = target_tensor.shape[1], input_tensor.shape[1]\n",
    "\n",
    "# Creating training and validation sets using an 90-10 split\n",
    "input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(input_tensor, target_tensor, test_size=0.1)\n",
    "\n",
    "# Show length\n",
    "tb_data = [[\"Eng Train Tensor\", len(input_tensor_train)], [\"Mar Train Tensor\",len(target_tensor_train)], \n",
    "           [\"Eng Val Tensor\", len(input_tensor_val)], [\"Mar Val Tensor\",len(target_tensor_val)]] \n",
    "\n",
    "print(tabulate(tb_data, headers=['','Lengths']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fd9a91e3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-18T13:51:44.778096Z",
     "iopub.status.busy": "2021-12-18T13:51:44.775867Z",
     "iopub.status.idle": "2021-12-18T13:51:44.887218Z",
     "shell.execute_reply": "2021-12-18T13:51:44.888083Z",
     "shell.execute_reply.started": "2021-12-18T13:27:36.653705Z"
    },
    "papermill": {
     "duration": 2.598109,
     "end_time": "2021-12-18T13:51:44.888275",
     "exception": false,
     "start_time": "2021-12-18T13:51:42.290166",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-18 13:51:42.366183: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-18 13:51:42.454881: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-18 13:51:42.455659: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-18 13:51:42.458125: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-12-18 13:51:42.458892: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-18 13:51:42.459801: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-18 13:51:42.460673: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-18 13:51:44.470378: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-18 13:51:44.471256: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-18 13:51:44.471921: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-18 13:51:44.472517: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15403 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(TensorShape([128, 44]), TensorShape([128, 40]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create TensorFlow Dataset\n",
    "\n",
    "BUFFER_SIZE = len(input_tensor_train)\n",
    "BATCH_SIZE = 128\n",
    "steps_per_epoch = len(input_tensor_train)//BATCH_SIZE\n",
    "embedding_dim = 256\n",
    "units = 1024\n",
    "vocab_inp_size = len(inp_lang.word_index)+1\n",
    "vocab_tar_size = len(targ_lang.word_index)+1\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((input_tensor_train, target_tensor_train)).shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
    "\n",
    "#Example Dataset\n",
    "example_input_batch, example_target_batch = next(iter(dataset))\n",
    "example_input_batch.shape, example_target_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "808ce86f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-18T13:51:44.928177Z",
     "iopub.status.busy": "2021-12-18T13:51:44.927388Z",
     "iopub.status.idle": "2021-12-18T13:51:44.929418Z",
     "shell.execute_reply": "2021-12-18T13:51:44.929795Z",
     "shell.execute_reply.started": "2021-12-18T13:27:38.924582Z"
    },
    "papermill": {
     "duration": 0.02518,
     "end_time": "2021-12-18T13:51:44.929932",
     "exception": false,
     "start_time": "2021-12-18T13:51:44.904752",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Encoder Class\n",
    "\n",
    "class Encoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.batch_sz = batch_sz\n",
    "        self.enc_units = enc_units\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.gru = tf.keras.layers.GRU(self.enc_units,\n",
    "                                       return_sequences=True,\n",
    "                                       return_state=True,\n",
    "                                       recurrent_initializer='glorot_uniform')\n",
    "\n",
    "    def call(self, x, hidden):\n",
    "        x = self.embedding(x)\n",
    "        output, state = self.gru(x, initial_state = hidden)\n",
    "        return output, state\n",
    "\n",
    "    def initialize_hidden_state(self):\n",
    "        return tf.zeros((self.batch_sz, self.enc_units))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "deabd660",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-18T13:51:44.966437Z",
     "iopub.status.busy": "2021-12-18T13:51:44.965904Z",
     "iopub.status.idle": "2021-12-18T13:51:46.069084Z",
     "shell.execute_reply": "2021-12-18T13:51:46.070251Z",
     "shell.execute_reply.started": "2021-12-18T13:27:38.934232Z"
    },
    "papermill": {
     "duration": 1.1246,
     "end_time": "2021-12-18T13:51:46.070497",
     "exception": false,
     "start_time": "2021-12-18T13:51:44.945897",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-18 13:51:45.833958: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder output shape: (batch size, sequence length, units) (128, 44, 1024)\n",
      "Encoder Hidden state shape: (batch size, units) (128, 1024)\n"
     ]
    }
   ],
   "source": [
    "#Encoding \n",
    "encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE)\n",
    "\n",
    "# Sample Input\n",
    "sample_hidden = encoder.initialize_hidden_state()\n",
    "sample_output, sample_hidden = encoder(example_input_batch, sample_hidden)\n",
    "\n",
    "print ('Encoder output shape: (batch size, sequence length, units) {}'.format(sample_output.shape))\n",
    "print ('Encoder Hidden state shape: (batch size, units) {}'.format(sample_hidden.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5164db1f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-18T13:51:46.139407Z",
     "iopub.status.busy": "2021-12-18T13:51:46.138514Z",
     "iopub.status.idle": "2021-12-18T13:51:46.143223Z",
     "shell.execute_reply": "2021-12-18T13:51:46.144186Z",
     "shell.execute_reply.started": "2021-12-18T13:27:39.858982Z"
    },
    "papermill": {
     "duration": 0.045627,
     "end_time": "2021-12-18T13:51:46.144393",
     "exception": false,
     "start_time": "2021-12-18T13:51:46.098766",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Bahdanau Attention Class\n",
    "\n",
    "class BahdanauAttention(tf.keras.layers.Layer):\n",
    "    \n",
    "    def __init__(self, units):\n",
    "        super(BahdanauAttention, self).__init__()\n",
    "        self.W1 = tf.keras.layers.Dense(units)\n",
    "        self.W2 = tf.keras.layers.Dense(units)\n",
    "        self.V = tf.keras.layers.Dense(1)\n",
    "\n",
    "    def call(self, query, values):\n",
    "        # query hidden state shape == (batch_size, hidden size)\n",
    "        # query_with_time_axis shape == (batch_size, 1, hidden size)\n",
    "        # values shape == (batch_size, max_len, hidden size)\n",
    "        # we are doing this to broadcast addition along the time axis to calculate the score\n",
    "        query_with_time_axis = tf.expand_dims(query, 1)\n",
    "\n",
    "        # score shape == (batch_size, max_length, 1)\n",
    "        # we get 1 at the last axis because we are applying score to self.V\n",
    "        # the shape of the tensor before applying self.V is (batch_size, max_length, units)\n",
    "        score = self.V(tf.nn.tanh(\n",
    "            self.W1(query_with_time_axis) + self.W2(values)))\n",
    "\n",
    "        # attention_weights shape == (batch_size, max_length, 1)\n",
    "        attention_weights = tf.nn.softmax(score, axis=1)\n",
    "\n",
    "        # context_vector shape after sum == (batch_size, hidden_size)\n",
    "        context_vector = attention_weights * values\n",
    "        context_vector = tf.reduce_sum(context_vector, axis=1)\n",
    "\n",
    "        return context_vector, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "64749d87",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-18T13:51:46.210465Z",
     "iopub.status.busy": "2021-12-18T13:51:46.209704Z",
     "iopub.status.idle": "2021-12-18T13:51:47.062154Z",
     "shell.execute_reply": "2021-12-18T13:51:47.062772Z",
     "shell.execute_reply.started": "2021-12-18T13:27:39.868656Z"
    },
    "papermill": {
     "duration": 0.890859,
     "end_time": "2021-12-18T13:51:47.062972",
     "exception": false,
     "start_time": "2021-12-18T13:51:46.172113",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention result shape: (batch size, units) (128, 1024)\n",
      "Attention weights shape: (batch_size, sequence_length, 1) (128, 44, 1)\n"
     ]
    }
   ],
   "source": [
    "# Attention\n",
    "attention_layer = BahdanauAttention(10)\n",
    "attention_result, attention_weights = attention_layer(sample_hidden, sample_output)\n",
    "\n",
    "print(\"Attention result shape: (batch size, units) {}\".format(attention_result.shape))\n",
    "print(\"Attention weights shape: (batch_size, sequence_length, 1) {}\".format(attention_weights.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "45b9eee2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-18T13:51:47.111522Z",
     "iopub.status.busy": "2021-12-18T13:51:47.104133Z",
     "iopub.status.idle": "2021-12-18T13:51:47.113561Z",
     "shell.execute_reply": "2021-12-18T13:51:47.114048Z",
     "shell.execute_reply.started": "2021-12-18T13:27:40.609034Z"
    },
    "papermill": {
     "duration": 0.031048,
     "end_time": "2021-12-18T13:51:47.114183",
     "exception": false,
     "start_time": "2021-12-18T13:51:47.083135",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Decoder Class\n",
    "\n",
    "class Decoder(tf.keras.Model):\n",
    "    \n",
    "    def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.batch_sz = batch_sz\n",
    "        self.dec_units = dec_units\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.gru = tf.keras.layers.GRU(self.dec_units,\n",
    "                                       return_sequences=True,\n",
    "                                       return_state=True,\n",
    "                                       recurrent_initializer='glorot_uniform')\n",
    "        self.fc = tf.keras.layers.Dense(vocab_size)\n",
    "\n",
    "        # used for attention\n",
    "        self.attention = BahdanauAttention(self.dec_units)\n",
    "\n",
    "    def call(self, x, hidden, enc_output):\n",
    "        # enc_output shape == (batch_size, max_length, hidden_size)\n",
    "        context_vector, attention_weights = self.attention(hidden, enc_output)\n",
    "\n",
    "        # x shape after passing through embedding == (batch_size, 1, embedding_dim)\n",
    "        x = self.embedding(x)\n",
    "\n",
    "        # x shape after concatenation == (batch_size, 1, embedding_dim + hidden_size)\n",
    "        x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
    "\n",
    "        # passing the concatenated vector to the GRU\n",
    "        output, state = self.gru(x)\n",
    "\n",
    "        # output shape == (batch_size * 1, hidden_size)\n",
    "        output = tf.reshape(output, (-1, output.shape[2]))\n",
    "\n",
    "        # output shape == (batch_size, vocab)\n",
    "        x = self.fc(output)\n",
    "\n",
    "        return x, state, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "231bd231",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-18T13:51:47.157103Z",
     "iopub.status.busy": "2021-12-18T13:51:47.156261Z",
     "iopub.status.idle": "2021-12-18T13:51:47.199125Z",
     "shell.execute_reply": "2021-12-18T13:51:47.198409Z",
     "shell.execute_reply.started": "2021-12-18T13:27:40.620107Z"
    },
    "papermill": {
     "duration": 0.066731,
     "end_time": "2021-12-18T13:51:47.199284",
     "exception": false,
     "start_time": "2021-12-18T13:51:47.132553",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoder output shape: (batch_size, vocab size) (128, 13890)\n"
     ]
    }
   ],
   "source": [
    "decoder = Decoder(vocab_tar_size, embedding_dim, units, BATCH_SIZE)\n",
    "\n",
    "sample_decoder_output, _, _ = decoder(tf.random.uniform((BATCH_SIZE, 1)),\n",
    "                                      sample_hidden, sample_output)\n",
    "\n",
    "print ('Decoder output shape: (batch_size, vocab size) {}'.format(sample_decoder_output.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dec1744d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-18T13:51:47.241729Z",
     "iopub.status.busy": "2021-12-18T13:51:47.240098Z",
     "iopub.status.idle": "2021-12-18T13:51:47.242377Z",
     "shell.execute_reply": "2021-12-18T13:51:47.242777Z",
     "shell.execute_reply.started": "2021-12-18T13:27:40.670682Z"
    },
    "papermill": {
     "duration": 0.024694,
     "end_time": "2021-12-18T13:51:47.242888",
     "exception": false,
     "start_time": "2021-12-18T13:51:47.218194",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Optimizer and Loss function\n",
    "optimizer = tf.keras.optimizers.Adamax()\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')\n",
    "\n",
    "def loss_function(real, pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    loss_ = loss_object(real, pred)\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ *= mask\n",
    "    return tf.reduce_mean(loss_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4987d01f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-18T13:51:47.284223Z",
     "iopub.status.busy": "2021-12-18T13:51:47.282610Z",
     "iopub.status.idle": "2021-12-18T13:51:47.284803Z",
     "shell.execute_reply": "2021-12-18T13:51:47.285196Z",
     "shell.execute_reply.started": "2021-12-18T13:27:40.679793Z"
    },
    "papermill": {
     "duration": 0.025064,
     "end_time": "2021-12-18T13:51:47.285355",
     "exception": false,
     "start_time": "2021-12-18T13:51:47.260291",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Check Points\n",
    "checkpoint_dir = './output/'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(optimizer=optimizer,encoder=encoder,decoder=decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "21578279",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-18T13:51:47.353156Z",
     "iopub.status.busy": "2021-12-18T13:51:47.352293Z",
     "iopub.status.idle": "2021-12-18T13:51:47.356841Z",
     "shell.execute_reply": "2021-12-18T13:51:47.359022Z",
     "shell.execute_reply.started": "2021-12-18T13:27:40.689723Z"
    },
    "papermill": {
     "duration": 0.052963,
     "end_time": "2021-12-18T13:51:47.359372",
     "exception": false,
     "start_time": "2021-12-18T13:51:47.306409",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Train Model Function\n",
    "\n",
    "@tf.function\n",
    "def train_step(inp, targ, enc_hidden):\n",
    "    loss = 0\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        enc_output, enc_hidden = encoder(inp, enc_hidden)\n",
    "\n",
    "        dec_hidden = enc_hidden\n",
    "\n",
    "        dec_input = tf.expand_dims([targ_lang.word_index['<start>']] * BATCH_SIZE, 1)\n",
    "\n",
    "        # Teacher forcing - feeding the target as the next input\n",
    "        for t in range(1, targ.shape[1]):\n",
    "            # passing enc_output to the decoder\n",
    "            predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output)\n",
    "            loss += loss_function(targ[:, t], predictions)\n",
    "            # using teacher forcing\n",
    "            dec_input = tf.expand_dims(targ[:, t], 1)\n",
    "\n",
    "    batch_loss = (loss / int(targ.shape[1]))\n",
    "\n",
    "    variables = encoder.trainable_variables + decoder.trainable_variables\n",
    "\n",
    "    gradients = tape.gradient(loss, variables)\n",
    "\n",
    "    optimizer.apply_gradients(zip(gradients, variables))\n",
    "\n",
    "    return batch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8fcfeadc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-18T13:51:47.449479Z",
     "iopub.status.busy": "2021-12-18T13:51:47.446305Z",
     "iopub.status.idle": "2021-12-18T14:13:53.121082Z",
     "shell.execute_reply": "2021-12-18T14:13:53.121740Z",
     "shell.execute_reply.started": "2021-12-18T13:27:40.700172Z"
    },
    "papermill": {
     "duration": 1325.725067,
     "end_time": "2021-12-18T14:13:53.121947",
     "exception": false,
     "start_time": "2021-12-18T13:51:47.396880",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-18 13:52:21.994576: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Batch 0 Loss 1.5855\n",
      "Epoch 1 Batch 100 Loss 0.9089\n",
      "Epoch 1 Batch 200 Loss 0.8471\n",
      "Epoch 1 Loss 0.9318\n",
      "Time taken for 1 epoch 170.23243737220764 sec\n",
      "\n",
      "Epoch 2 Batch 0 Loss 0.8668\n",
      "Epoch 2 Batch 100 Loss 0.8686\n",
      "Epoch 2 Batch 200 Loss 0.7680\n",
      "Epoch 2 Loss 0.8117\n",
      "Time taken for 1 epoch 128.59540605545044 sec\n",
      "\n",
      "Epoch 3 Batch 0 Loss 0.7535\n",
      "Epoch 3 Batch 100 Loss 0.7708\n",
      "Epoch 3 Batch 200 Loss 0.7652\n",
      "Epoch 3 Loss 0.7673\n",
      "Time taken for 1 epoch 127.95656251907349 sec\n",
      "\n",
      "Epoch 4 Batch 0 Loss 0.7168\n",
      "Epoch 4 Batch 100 Loss 0.6768\n",
      "Epoch 4 Batch 200 Loss 0.6776\n",
      "Epoch 4 Loss 0.7217\n",
      "Time taken for 1 epoch 128.73822689056396 sec\n",
      "\n",
      "Epoch 5 Batch 0 Loss 0.6727\n",
      "Epoch 5 Batch 100 Loss 0.6510\n",
      "Epoch 5 Batch 200 Loss 0.6523\n",
      "Epoch 5 Loss 0.6850\n",
      "Time taken for 1 epoch 127.95248126983643 sec\n",
      "\n",
      "Epoch 6 Batch 0 Loss 0.6585\n",
      "Epoch 6 Batch 100 Loss 0.6656\n",
      "Epoch 6 Batch 200 Loss 0.6497\n",
      "Epoch 6 Loss 0.6564\n",
      "Time taken for 1 epoch 128.68668484687805 sec\n",
      "\n",
      "Epoch 7 Batch 0 Loss 0.6778\n",
      "Epoch 7 Batch 100 Loss 0.6231\n",
      "Epoch 7 Batch 200 Loss 0.6095\n",
      "Epoch 7 Loss 0.6315\n",
      "Time taken for 1 epoch 127.97848129272461 sec\n",
      "\n",
      "Epoch 8 Batch 0 Loss 0.5721\n",
      "Epoch 8 Batch 100 Loss 0.5827\n",
      "Epoch 8 Batch 200 Loss 0.6065\n",
      "Epoch 8 Loss 0.6092\n",
      "Time taken for 1 epoch 128.71921801567078 sec\n",
      "\n",
      "Epoch 9 Batch 0 Loss 0.6496\n",
      "Epoch 9 Batch 100 Loss 0.6139\n",
      "Epoch 9 Batch 200 Loss 0.5818\n",
      "Epoch 9 Loss 0.5894\n",
      "Time taken for 1 epoch 128.01697731018066 sec\n",
      "\n",
      "Epoch 10 Batch 0 Loss 0.6028\n",
      "Epoch 10 Batch 100 Loss 0.5044\n",
      "Epoch 10 Batch 200 Loss 0.6011\n",
      "Epoch 10 Loss 0.5706\n",
      "Time taken for 1 epoch 128.76672220230103 sec\n",
      "\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 10\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    start = time.time()\n",
    "\n",
    "    enc_hidden = encoder.initialize_hidden_state()\n",
    "    total_loss = 0\n",
    "\n",
    "    for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):\n",
    "        batch_loss = train_step(inp, targ, enc_hidden)\n",
    "        total_loss += batch_loss\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1,\n",
    "                                                   batch,\n",
    "                                                   batch_loss.numpy()))\n",
    "    # saving (checkpoint) the model every 2 epochs\n",
    "    if (epoch + 1) % 2 == 0:\n",
    "        checkpoint.save(file_prefix = checkpoint_prefix)\n",
    "\n",
    "    print('Epoch {} Loss {:.4f}'.format(epoch + 1,\n",
    "                                      total_loss / steps_per_epoch))\n",
    "    print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b9c9c2d7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-18T14:13:53.666769Z",
     "iopub.status.busy": "2021-12-18T14:13:53.665954Z",
     "iopub.status.idle": "2021-12-18T14:13:53.668713Z",
     "shell.execute_reply": "2021-12-18T14:13:53.669239Z",
     "shell.execute_reply.started": "2021-12-18T13:49:45.078634Z"
    },
    "papermill": {
     "duration": 0.518841,
     "end_time": "2021-12-18T14:13:53.669393",
     "exception": false,
     "start_time": "2021-12-18T14:13:53.150552",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "982083b9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-18T14:13:53.736955Z",
     "iopub.status.busy": "2021-12-18T14:13:53.735388Z",
     "iopub.status.idle": "2021-12-18T14:13:53.737542Z",
     "shell.execute_reply": "2021-12-18T14:13:53.737948Z",
     "shell.execute_reply.started": "2021-12-18T13:49:45.562873Z"
    },
    "papermill": {
     "duration": 0.040219,
     "end_time": "2021-12-18T14:13:53.738079",
     "exception": false,
     "start_time": "2021-12-18T14:13:53.697860",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Evaluate Function\n",
    "\n",
    "def evaluate(sentence):\n",
    "    attention_plot = np.zeros((max_length_targ, max_length_inp))\n",
    "\n",
    "    sentence = preprocess(sentence)\n",
    "\n",
    "    inputs = [inp_lang.word_index[i] for i in sentence.split(' ')]\n",
    "    inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs],\n",
    "                                                         maxlen=max_length_inp,\n",
    "                                                         padding='post')\n",
    "  \n",
    "    inputs = tf.convert_to_tensor(inputs)\n",
    "\n",
    "    result = ''\n",
    "\n",
    "    hidden = [tf.zeros((1, units))]\n",
    "    enc_out, enc_hidden = encoder(inputs, hidden)\n",
    "\n",
    "    dec_hidden = enc_hidden\n",
    "    dec_input = tf.expand_dims([targ_lang.word_index['<start>']], 0)\n",
    "\n",
    "    for t in range(max_length_targ):\n",
    "        predictions, dec_hidden, attention_weights = decoder(dec_input,\n",
    "                                                         dec_hidden,\n",
    "                                                         enc_out)\n",
    "\n",
    "        # storing the attention weights to plot later on\n",
    "        attention_weights = tf.reshape(attention_weights, (-1, ))\n",
    "        attention_plot[t] = attention_weights.numpy()\n",
    "\n",
    "        predicted_id = tf.argmax(predictions[0]).numpy()\n",
    "\n",
    "        result += targ_lang.index_word[predicted_id] + ' '\n",
    "\n",
    "        if targ_lang.index_word[predicted_id] == '<end>':\n",
    "            return result, sentence, attention_plot\n",
    "\n",
    "        # the predicted ID is fed back into the model\n",
    "        dec_input = tf.expand_dims([predicted_id], 0)\n",
    "\n",
    "    return result, sentence, attention_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5dd4ca3c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-18T14:13:53.798333Z",
     "iopub.status.busy": "2021-12-18T14:13:53.797515Z",
     "iopub.status.idle": "2021-12-18T14:13:53.799447Z",
     "shell.execute_reply": "2021-12-18T14:13:53.799830Z",
     "shell.execute_reply.started": "2021-12-18T13:49:45.584886Z"
    },
    "papermill": {
     "duration": 0.033977,
     "end_time": "2021-12-18T14:13:53.799960",
     "exception": false,
     "start_time": "2021-12-18T14:13:53.765983",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Function to Translate\n",
    "def translate(sentence):\n",
    "    result, sentence, attention_plot = evaluate(sentence)\n",
    "\n",
    "    print('Input: %s' % (sentence))\n",
    "    print('Predicted translation: {}'.format(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f001477a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-18T14:13:53.859762Z",
     "iopub.status.busy": "2021-12-18T14:13:53.859267Z",
     "iopub.status.idle": "2021-12-18T14:13:53.915711Z",
     "shell.execute_reply": "2021-12-18T14:13:53.915098Z",
     "shell.execute_reply.started": "2021-12-18T13:50:56.688026Z"
    },
    "papermill": {
     "duration": 0.088192,
     "end_time": "2021-12-18T14:13:53.915850",
     "exception": false,
     "start_time": "2021-12-18T14:13:53.827658",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: <start> this is book <end>\n",
      "Predicted translation: हे पुस्तक आहे . <end> \n"
     ]
    }
   ],
   "source": [
    "#Translate\n",
    "translate(\"this is book\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1351.450062,
   "end_time": "2021-12-18T14:13:56.655174",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-12-18T13:51:25.205112",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
